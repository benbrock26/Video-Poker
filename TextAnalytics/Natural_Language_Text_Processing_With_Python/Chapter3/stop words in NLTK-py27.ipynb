{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'all', u'just', u\"don't\", u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'don', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u\"should've\", u\"haven't\", u'do', u'them', u'his', u'very', u\"you've\", u'they', u'not', u'during', u'now', u'him', u'nor', u\"wasn't\", u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u\"won't\", u'where', u\"mustn't\", u\"isn't\", u'few', u'because', u\"you'd\", u'doing', u'some', u'hasn', u\"hasn't\", u'are', u'our', u'ourselves', u'out', u'what', u'for', u\"needn't\", u'below', u're', u'does', u\"shouldn't\", u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u\"mightn't\", u\"doesn't\", u'were', u'here', u'shouldn', u'hers', u\"aren't\", u'by', u'on', u'about', u'couldn', u'of', u\"wouldn't\", u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u\"hadn't\", u'mightn', u\"couldn't\", u'wasn', u'your', u\"you're\", u'from', u'her', u'their', u'aren', u\"it's\", u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u\"didn't\", u'but', u\"that'll\", u'with', u'than', u'those', u'he', u'me', u'myself', u'ma', u\"weren't\", u'these', u'up', u'will', u'while', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u\"shan't\", u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u\"you'll\", u'so', u'y', u\"she's\", u'the', u'having', u'once'])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "english_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "print(english_stopwords)\n",
    "# I used \"set\" because they are fast for checking membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'son', u'ten\\xeda', u'estar\\xe1', u'estadas', u'tengamos', u'hubieras', u'sentidos', u'nuestra', u'teng\\xe1is', u'\\xe9l', u'tuvi\\xe9semos', u'estos', u'tuvimos', u'tuviste', u'nuestro', u'otro', u'tuvieron', u'antes', u'le', u'han', u'la', u'estar\\xedamos', u'lo', u'estar\\xedas', u'tu', u'ten\\xedamos', u'quienes', u'otra', u'hubi\\xe9semos', u'hay', u'suyas', u'tendr\\xe9', u'ti', u'estar', u'te', u'ten\\xe9is', u'habr\\xedas', u'tendr\\xe1', u'porque', u'estuvimos', u'ser\\xedais', u'estaba', u'esa', u'yo', u'\\xe9ramos', u'ya', u'cuando', u'nada', u'de', u'est\\xe1is', u'tuyos', u'hayan', u'tendr\\xe9is', u'estuve', u'algunos', u'hayas', u'tanto', u'qu\\xe9', u'seas', u'vosostros', u'm\\xeda', u'tuvieras', u'nos', u'hubimos', u'est\\xe9is', u'estoy', u'estaremos', u'hubieran', u'una', u'tuvieran', u'estar\\xe9is', u'somos', u'fu\\xe9semos', u'desde', u'sentida', u'habr\\xe9', u'nosotras', u'estados', u'sentido', u'habr\\xe1', u'el', u'fuera', u'en', u'habr\\xeda', u'esos', u'tendr\\xe1n', u'otras', u'habr\\xe9is', u'ten\\xedas', u'fuesen', u'fue', u'hubieseis', u'tenida', u'soy', u'fueseis', u'seamos', u'hube', u'sea', u'tuviese', u'tendr\\xedamos', u'estamos', u'todo', u'es', u'eres', u'estad', u'tuya', u't\\xfa', u'tuvieseis', u'fueses', u'hab\\xedas', u'm\\xedas', u'tenido', u'muy', u'tuyo', u'algunas', u'poco', u'ese', u'haya', u'sus', u'estas', u'sobre', u'ser\\xedamos', u'eso', u'hab\\xedais', u'tened', u'estar\\xe9', u'era', u'fuerais', u'habr\\xedan', u'estuvieran', u'tienen', u'fuiste', u'tuvo', u'tus', u'fu\\xe9ramos', u'estar\\xedais', u'les', u'que', u'como', u'estuvieras', u'habido', u'tengan', u'tendr\\xe1s', u'tenidas', u'ser\\xedas', u'estar\\xe1s', u'estuvierais', u'hab\\xeda', u'estuvo', u'eras', u'estuviera', u'estuvisteis', u'tuvierais', u'o', u'ser\\xe1s', u'est\\xe1bamos', u'tambi\\xe9n', u'ser\\xe1n', u'nosotros', u'algo', u'quien', u'fui', u'os', u'ser\\xe9is', u'uno', u'hab\\xedan', u'hubiera', u'habiendo', u'est\\xe1', u'teniendo', u'fuisteis', u'por', u'est\\xe9', u'durante', u'mucho', u'suya', u'donde', u'estuvieron', u'tendremos', u'erais', u'ante', u'tuvisteis', u'otros', u'estaban', u'suyo', u'tienes', u'fueron', u'tenemos', u'tuvieses', u'contra', u'esas', u'estado', u'pero', u'est\\xe9s', u'estemos', u'est\\xe9n', u'los', u'estabas', u'nuestros', u'est\\xe1s', u'ellos', u'tuvi\\xe9ramos', u'estar\\xe1n', u'fueran', u'suyos', u'habidos', u'hubiese', u'tendr\\xedais', u'm\\xe1s', u'vuestros', u'm\\xedos', u'estabais', u'para', u'fuese', u'fuimos', u'estar\\xedan', u'tendr\\xedas', u'fueras', u'estuvieseis', u'tendr\\xedan', u'vuestro', u'vuestra', u'ha', u'ten\\xedais', u'estuviese', u'he', u'me', u'has', u'hubo', u'seremos', u'hab\\xe9is', u'hubi\\xe9ramos', u'mi', u'tengo', u'est\\xe1n', u'ten\\xedan', u'sintiendo', u'un', u'del', u'hemos', u's\\xed', u'tuviera', u'tengas', u'sean', u'habr\\xedais', u'este', u'unos', u'esta', u'habr\\xe1n', u'estando', u'eran', u'esto', u'al', u'hayamos', u'hab\\xedamos', u'hay\\xe1is', u'hubieses', u'sois', u'tenidos', u'habr\\xe1s', u'tenga', u'ni', u'tuviesen', u'no', u'estuvieses', u'ellas', u'sentidas', u'tiene', u'habr\\xedamos', u'se\\xe1is', u'estuviesen', u'cual', u'nuestras', u'mis', u'sin', u'todos', u'vosostras', u'hubisteis', u'tuyas', u'habremos', u'tuve', u'hubiste', u'ella', u'sentid', u'hubierais', u'hubieron', u'estada', u'siente', u'ser\\xeda', u'estar\\xeda', u'las', u'a', u'vuestras', u'estuvi\\xe9ramos', u'e', u'entre', u'habida', u'm\\xed', u'ser\\xedan', u'muchos', u'm\\xedo', u'su', u'hasta', u'estuvi\\xe9semos', u'hubiesen', u'ser\\xe1', u'y', u'habidas', u'tendr\\xeda', u'con', u'estuviste', u'se', u'ser\\xe9'])\n"
     ]
    }
   ],
   "source": [
    "spanish_stopwords = set(nltk.corpus.stopwords.words('spanish'))\n",
    "print(spanish_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chicken', 'went', 'house', 'humiliate', 'man', '.']\n"
     ]
    }
   ],
   "source": [
    "# Here we remove stop words to get the gist of a sentence\n",
    "from nltk.tokenize import word_tokenize\n",
    "text = \"The chicken went to the house to humiliate the man.\"\n",
    "tokens = word_tokenize(text)\n",
    "content_tokens = [token for token in tokens if token.lower() not in english_stopwords]\n",
    "print(content_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good time to introduce the NLP bible\n",
    "http://www.cs.colorado.edu/~martin/slp2.html\n",
    "\n",
    "## Third edition in preparation and you can read some of the chapters free online\n",
    "https://web.stanford.edu/~jurafsky/slp3/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
